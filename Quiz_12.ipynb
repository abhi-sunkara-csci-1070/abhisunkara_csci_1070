{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6edf3cec-72e3-4d68-a2fe-30bfda7464f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0171e2d-223c-4e54-9c0f-b5fd8324d5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv(\"../week_06/diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6dbcb0b7-789b-453b-af27-20503ddd5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1).values\n",
    "y = diabetes_df['Outcome'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e97d403e-4bf7-43b2-a33a-7c40bb223007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  7.0000, 184.0000,  84.0000,  ...,  35.5000,   0.3550,  41.0000],\n",
      "        [  6.0000,  85.0000,  78.0000,  ...,  31.2000,   0.3820,  42.0000],\n",
      "        [  2.0000, 106.0000,  64.0000,  ...,  30.5000,   1.4000,  34.0000],\n",
      "        ...,\n",
      "        [  1.0000,  97.0000,  70.0000,  ...,  38.1000,   0.2180,  30.0000],\n",
      "        [  6.0000, 190.0000,  92.0000,  ...,  35.5000,   0.2780,  66.0000],\n",
      "        [  4.0000, 144.0000,  58.0000,  ...,  29.5000,   0.2870,  37.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # functional has the activation functions\n",
    "\n",
    "#create tensors from the data\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_test = torch.LongTensor(y_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85708967-ff4d-4054-8f73-aa47c0f8cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self,input_features=8,\n",
    "                 hidden1=20,hidden2=20,\n",
    "                 out_features=2):\n",
    "        super().__init__() \n",
    "\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "616872a9-3286-4632-b0cd-b557f9599ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35c2f170-bc0c-46ca-9b6d-991982d6f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = nn.CrossEntropyLoss()\n",
    "op = torch.optim.ASGD(a.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6816711a-59e0-4a82-b65e-937c10c56cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 with loss 1.1355774402618408\n",
      "Epoch number: 11 with loss 0.6555914282798767\n",
      "Epoch number: 21 with loss 0.6423352956771851\n",
      "Epoch number: 31 with loss 0.6323494911193848\n",
      "Epoch number: 41 with loss 0.6244580745697021\n",
      "Epoch number: 51 with loss 0.6166220903396606\n",
      "Epoch number: 61 with loss 0.6053234338760376\n",
      "Epoch number: 71 with loss 0.6316350698471069\n",
      "Epoch number: 81 with loss 0.6016599535942078\n",
      "Epoch number: 91 with loss 0.6057071685791016\n",
      "Epoch number: 101 with loss 0.5966047048568726\n",
      "Epoch number: 111 with loss 0.593591570854187\n",
      "Epoch number: 121 with loss 0.592191755771637\n",
      "Epoch number: 131 with loss 0.5850436687469482\n",
      "Epoch number: 141 with loss 0.5847897529602051\n",
      "Epoch number: 151 with loss 0.5768356919288635\n",
      "Epoch number: 161 with loss 0.5774110555648804\n",
      "Epoch number: 171 with loss 0.5708922743797302\n",
      "Epoch number: 181 with loss 0.5704488754272461\n",
      "Epoch number: 191 with loss 0.570472776889801\n",
      "Epoch number: 201 with loss 0.5647780299186707\n",
      "Epoch number: 211 with loss 0.5655359625816345\n",
      "Epoch number: 221 with loss 0.564980149269104\n",
      "Epoch number: 231 with loss 0.5616527795791626\n",
      "Epoch number: 241 with loss 0.5594679117202759\n",
      "Epoch number: 251 with loss 0.5579925179481506\n",
      "Epoch number: 261 with loss 0.5575313568115234\n",
      "Epoch number: 271 with loss 0.5555965900421143\n",
      "Epoch number: 281 with loss 0.5536410212516785\n",
      "Epoch number: 291 with loss 0.5528103113174438\n",
      "Epoch number: 301 with loss 0.5526467561721802\n",
      "Epoch number: 311 with loss 0.5532402992248535\n",
      "Epoch number: 321 with loss 0.5522772669792175\n",
      "Epoch number: 331 with loss 0.5488460659980774\n",
      "Epoch number: 341 with loss 0.5467660427093506\n",
      "Epoch number: 351 with loss 0.5454813241958618\n",
      "Epoch number: 361 with loss 0.5431100726127625\n",
      "Epoch number: 371 with loss 0.5422337055206299\n",
      "Epoch number: 381 with loss 0.5412699580192566\n",
      "Epoch number: 391 with loss 0.5415269136428833\n",
      "Epoch number: 401 with loss 0.5382533669471741\n",
      "Epoch number: 411 with loss 0.5377616286277771\n",
      "Epoch number: 421 with loss 0.5386908054351807\n",
      "Epoch number: 431 with loss 0.5365819931030273\n",
      "Epoch number: 441 with loss 0.5371930599212646\n",
      "Epoch number: 451 with loss 0.5345165729522705\n",
      "Epoch number: 461 with loss 0.5332559943199158\n",
      "Epoch number: 471 with loss 0.5323882102966309\n",
      "Epoch number: 481 with loss 0.5309672951698303\n",
      "Epoch number: 491 with loss 0.5302082300186157\n"
     ]
    }
   ],
   "source": [
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for i in range(n_epochs):\n",
    "    y_pred = a.forward(X_train)\n",
    "    l = ln(y_pred, y_train)\n",
    "    final_loss.append(loss)\n",
    "\n",
    "    if i % 10 == 1:\n",
    "        print(f'Epoch number: {i} with loss {l}')\n",
    "\n",
    "    op.zero_grad()\n",
    "    l.backward()\n",
    "    op.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c30f2-7a65-4877-8286-09fa7830c4cd",
   "metadata": {},
   "source": [
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for a, data in enumerate(X_test):\n",
    "        prediction = a(data)\n",
    "        y_pred.append(prediction.argmax()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "675c9862-e734-4760-b2c7-cdf6e35ce12e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [231, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay\n\u001b[0;32m----> 2\u001b[0m \u001b[43mConfusionMatrixDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5/libexec/lib/python3.12/site-packages/sklearn/metrics/_plot/confusion_matrix.py:463\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.from_predictions\u001b[0;34m(cls, y_true, y_pred, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m         display_labels \u001b[38;5;241m=\u001b[39m labels\n\u001b[0;32m--> 463\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m disp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(confusion_matrix\u001b[38;5;241m=\u001b[39mcm, display_labels\u001b[38;5;241m=\u001b[39mdisplay_labels)\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disp\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m    474\u001b[0m     include_values\u001b[38;5;241m=\u001b[39minclude_values,\n\u001b[1;32m    475\u001b[0m     cmap\u001b[38;5;241m=\u001b[39mcmap,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m     text_kw\u001b[38;5;241m=\u001b[39mtext_kw,\n\u001b[1;32m    482\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5/libexec/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5/libexec/lib/python3.12/site-packages/sklearn/metrics/_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    248\u001b[0m     {\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    259\u001b[0m ):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    (np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5/libexec/lib/python3.12/site-packages/sklearn/metrics/_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5/libexec/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [231, 0]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c12861b0-c2c1-4b06-9be6-0e30c1f39b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5974025974025974"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall with Adam\n",
    "46/(46+31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d73cfd1b-09d3-4edc-9e1f-65861efa4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Recall with ASGD\n",
    "30 / (30 + 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2c154-6e05-4daa-b867-96ee758468fe",
   "metadata": {},
   "source": [
    "### \n",
    "The Adam Optimization function uses 2 algorithms and takes the average of both of them. These two algorithms are Adaptive Gradient Algorithm and Root Mean Square Propagation. ASGD optimization led the model to perform well because the calculated recall was better. In my opinion, this is probablly because the ASGD is a much simpler process, as AGD averages the sum of all the weight tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce792d45-0c49-4837-bba0-62beaae92a98",
   "metadata": {},
   "source": [
    "### Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8b726eb-423b-4ff9-afda-2f5c9e8ffc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 8 divisors: 1, 2, 4, 5, 8, 10, 20, and 40.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def divisors(n: int) -> str:\n",
    "    d = []\n",
    "    for a in range(1, number + 1):\n",
    "        if number % a == 0:\n",
    "            d.append(num)\n",
    "    answer = \"\"\n",
    "    for l in range(0, len(divisors) - 1):\n",
    "        answer += str(divisors[l]) + \", \"\n",
    "    answer += \"and \" + str(divisors[len(divisors) - 1])\n",
    "    result = f'There are {len(divisors)} divisors: {answer}.'\n",
    "    return result\n",
    "\n",
    "num_divisors(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e56b6-cce4-4df4-9cda-14f7f1a250d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
